# Diagrama de Flujo - Pipeline de PredicciÃ³n de Productos Prioritarios

## Diagrama Principal

```mermaid
flowchart TD
    Start([Start Pipeline]) --> CheckHist{Check Historical<br/>Data}

    %% Primera bifurcaciÃ³n: Â¿Existe histÃ³rico?
    CheckHist -->|No existe| CopyRaw[Copy Raw<br/>to Historical]
    CheckHist -->|Existe| Pass1[Pass 1<br/>Empty]

    %% Ambas ramas convergen
    CopyRaw --> CheckNew{Check New<br/>Data}
    Pass1 --> CheckNew

    %% Segunda bifurcaciÃ³n: Â¿Hay datos nuevos?
    CheckNew -->|Hay nuevos| ExtendDS[Extend Dataset<br/>Agregar nuevas filas]
    CheckNew -->|No hay nuevos| Pass2[Pass 2<br/>Empty]

    %% Ambas ramas convergen
    ExtendDS --> DecideTrain{Decide Training<br/>Â¿Se ejecutÃ³ copy_raw<br/>o extend_dataset?}
    Pass2 --> DecideTrain

    %% Tercera bifurcaciÃ³n: Â¿Entrenar modelo?
    DecideTrain -->|SÃ­ entrenar| PrepData[Prepare Data<br/>Limpieza y agregaciÃ³n]
    DecideTrain -->|No entrenar| NotTrain[Not Train<br/>Empty]

    %% Flujo de entrenamiento
    PrepData --> Split[Split Data<br/>Train/Val/Test]
    Split --> Preproc[Preprocess Data<br/>Pipeline de preprocesamiento]

    %% Cuarta bifurcaciÃ³n: Â¿Optimizar hiperparÃ¡metros?
    Preproc --> CheckOptimize{Check if Should<br/>Optimize<br/>Â¿Existe best_params?<br/>Â¿Semanas >= 4?<br/>Â¿FORCE_REOPTIMIZE?}
    CheckOptimize -->|Optimizar| Optimize[Optimize Model<br/>30 trials Optuna<br/>Guardar best_params]
    CheckOptimize -->|Cargar existentes| LoadParams[Load Best Params<br/>Leer best_params.json<br/>Incrementar semanas]

    %% BifurcaciÃ³n en paralelo (cross_downstream)
    Optimize --> Evaluate[Evaluate and Interpret<br/>SHAP + MLflow]
    Optimize --> TrainFinal[Train Final Model<br/>Con todos los datos]
    LoadParams --> Evaluate
    LoadParams --> TrainFinal

    %% Convergencia final
    Evaluate --> End([End Pipeline])
    TrainFinal --> End
    NotTrain --> End

    %% Estilos
    classDef startEnd fill:#90EE90,stroke:#333,stroke-width:3px
    classDef decision fill:#FFD700,stroke:#333,stroke-width:2px
    classDef process fill:#87CEEB,stroke:#333,stroke-width:2px
    classDef empty fill:#D3D3D3,stroke:#333,stroke-width:1px
    classDef important fill:#FF6B6B,stroke:#333,stroke-width:2px
    classDef smart fill:#9B59B6,stroke:#333,stroke-width:2px

    class Start,End startEnd
    class CheckHist,CheckNew,DecideTrain,CheckOptimize decision
    class PrepData,Split,Preproc,Evaluate,TrainFinal process
    class Pass1,Pass2,NotTrain empty
    class CopyRaw,ExtendDS important
    class Optimize,LoadParams smart
```

## Leyenda de Colores

- ğŸŸ¢ **Verde**: Inicio y fin del pipeline
- ğŸŸ¡ **Amarillo**: Puntos de decisiÃ³n (branching)
- ğŸ”µ **Azul**: Tareas de procesamiento y modelado
- âšª **Gris**: Operadores vacÃ­os (pass)
- ğŸ”´ **Rojo**: Tareas crÃ­ticas de datos (copy_raw, extend_dataset)
- ğŸŸ£ **Morado**: OptimizaciÃ³n inteligente (optimize_model, load_best_params)

## Flujos Posibles

### Escenario 1: Primera EjecuciÃ³n (sin best_params.json)
```
Start â†’ Check Historical (no existe) â†’ Copy Raw â†’ Check New (no hay) â†’
Pass 2 â†’ Decide Training (sÃ­) â†’ Prepare Data â†’ Split â†’ Preprocess â†’
Check Optimize (no existe params) â†’ Optimize Model (30 trials) â†’
[Evaluate + Train Final] â†’ End
```
**Tiempo**: ~15-20 minutos (optimizaciÃ³n completa)

### Escenario 2: Reentrenamiento con Datos Nuevos (semanas < 4)
```
Start â†’ Check Historical (existe) â†’ Pass 1 â†’ Check New (hay nuevos) â†’
Extend Dataset â†’ Decide Training (sÃ­) â†’ Prepare Data â†’ Split â†’ Preprocess â†’
Check Optimize (params existen, semanas < 4) â†’ Load Best Params â†’
[Evaluate + Train Final] â†’ End
```
**Tiempo**: ~2-5 minutos (carga params, solo entrenamiento)

### Escenario 3: EjecuciÃ³n sin Datos Nuevos
```
Start â†’ Check Historical (existe) â†’ Pass 1 â†’ Check New (no hay) â†’
Pass 2 â†’ Decide Training (no) â†’ Not Train â†’ End
```
**Tiempo**: ~10 segundos (solo verificaciones)

### Escenario 4: Re-optimizaciÃ³n PeriÃ³dica (semanas >= 4)
```
Start â†’ Check Historical (existe) â†’ Pass 1 â†’ Check New (hay nuevos) â†’
Extend Dataset â†’ Decide Training (sÃ­) â†’ Prepare Data â†’ Split â†’ Preprocess â†’
Check Optimize (semanas >= 4) â†’ Optimize Model (30 trials) â†’
[Evaluate + Train Final] â†’ End
```
**Tiempo**: ~15-20 minutos (re-optimizaciÃ³n completa)

### Escenario 5: Re-optimizaciÃ³n Forzada (FORCE_REOPTIMIZE=true)
```
Start â†’ Check Historical (existe) â†’ Pass 1 â†’ Check New (puede o no haber) â†’
[Extend Dataset o Pass 2] â†’ Decide Training (sÃ­) â†’ Prepare Data â†’ Split â†’ Preprocess â†’
Check Optimize (FORCE_REOPTIMIZE) â†’ Optimize Model (30 trials) â†’
[Evaluate + Train Final] â†’ End
```
**Tiempo**: ~15-20 minutos (re-optimizaciÃ³n forzada)

## Puntos Clave del DiseÃ±o

1. **Cuatro decisiones principales**:
   - Â¿Existe dataset histÃ³rico? (primera vez vs. ejecuciones posteriores)
   - Â¿Hay datos nuevos? (reentrenamiento necesario)
   - Â¿Entrenar modelo? (basado en las dos decisiones anteriores)
   - Â¿Optimizar hiperparÃ¡metros? (nueva lÃ³gica inteligente para reducir tiempo)

2. **OptimizaciÃ³n Inteligente** (NUEVA):
   - **Primera ejecuciÃ³n**: Optimiza con 30 trials y guarda `best_hyperparameters.json`
   - **Reentrenamientos regulares**: Carga params existentes (ahorro de ~10-15 minutos)
   - **Re-optimizaciÃ³n periÃ³dica**: Cada 4 semanas se re-optimizan los hiperparÃ¡metros
   - **Re-optimizaciÃ³n forzada**: Variable `FORCE_REOPTIMIZE=true` fuerza optimizaciÃ³n
   - **Contador de semanas**: Se incrementa en cada ejecuciÃ³n que carga params

3. **ParalelizaciÃ³n**:
   - `evaluate_and_interpret` y `train_final_model` se ejecutan en paralelo
   - Usando `cross_downstream` despuÃ©s de `optimize_model` o `load_best_params`

4. **Predicciones on-demand**:
   - Las predicciones se generan a travÃ©s de la aplicaciÃ³n web, no en el DAG
   - El DAG se enfoca exclusivamente en entrenamiento y reentrenamiento del modelo

5. **Trigger Rules**:
   - `decide_training` usa `none_failed` para ejecutarse si cualquier rama upstream tuvo Ã©xito
   - `evaluate_and_interpret` y `train_final_model` usan `none_failed` para ejecutarse despuÃ©s de cualquier rama
   - `end_pipeline` tambiÃ©n usa `none_failed` para ejecutarse siempre
```

---

## Diagrama Simplificado (Alto Nivel)

```mermaid
flowchart LR
    A[ğŸ“¥ Inicio] --> B[ğŸ” GestiÃ³n<br/>de Datos]
    B --> C{Â¿Entrenar?}
    C -->|SÃ­| D[âš™ï¸ PreparaciÃ³n<br/>de Datos]
    C -->|No| H[âœ… Fin]
    D --> F[ğŸ¯ OptimizaciÃ³n<br/>+ EvaluaciÃ³n]
    F --> H

    classDef phase fill:#4A90E2,stroke:#333,color:#fff
    class B,D,F phase
```
