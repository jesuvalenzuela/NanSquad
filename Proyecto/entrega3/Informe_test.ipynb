{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "516acf1d6e9d4ddb9a8acdeb6b1cca14",
        "deepnote_app_block_visible": true,
        "deepnote_cell_type": "markdown",
        "id": "-MGJGjPDimJI"
      },
      "source": [
        "![](https://www.dii.uchile.cl/wp-content/uploads/2021/06/Magi%CC%81ster-en-Ciencia-de-Datos.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "befdb70375f04ab79952117eb63723e7",
        "deepnote_app_block_visible": true,
        "deepnote_cell_type": "markdown",
        "id": "SN4W-_BNimJJ"
      },
      "source": [
        "**MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**DISCLAIMER üì£**\n",
        "\n",
        "**En este proyecto utilizamos un enfoque de top-N recomendaciones, ya que observamos que el modelo tiende a asignar probabilidades bajas y muy cercanas entre s√≠ debido al fuerte desbalance de clases. Bajo este escenario, elegir un umbral fijo generaba poca estabilidad y un rendimiento inconsistente entre batches. En cambio, seleccionar siempre los N productos m√°s probables por cliente permiti√≥ controlar mejor el volumen de recomendaciones, reducir la sensibilidad al threshold y obtener resultados m√°s coherentes con el comportamiento real del modelo. NO ES NECESARIO QUE HAGAN ESTE MISMO PROCEDIMIENTO, ES SOLO PARA GUIARLOS**\n",
        "\n",
        "**El desempe√±o de su modelo depender√° de como crearon los datos hist√≥ricos de transacciones por lo que les puede tomar mucho tiempo o poco el entrenamiento, les adjuntamos un codigo de como lo trabajamos en la secci√≥n de an√°lisis. Sus an√°lisis pueden variar en las distintas pruebas de los batches, no se desanimen si les dan malos resultados. Procuren de realizar un an√°lisis por semana en conjunto con un an√°lisis general de todos los batches.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GjshSnpjGcr"
      },
      "source": [
        "### **Instrucciones importantes**\n",
        "\n",
        "1. **Formato del informe**:  \n",
        "   - El informe debe estar integrado dentro de un **Jupyter Notebook**. No es necesario subirlo a una plataforma externa, pero debe cumplir con los siguientes requisitos:  \n",
        "     - Estructura clara y ordenada.  \n",
        "     - C√≥digo acompa√±ado de explicaciones detalladas.  \n",
        "     - Resultados presentados de forma visual y anal√≠tica.  \n",
        "\n",
        "2. **Descuento por informes deficientes**:  \n",
        "   - Cualquier secci√≥n del informe que no tenga una explicaci√≥n adecuada o no respete el formato ser√° penalizada con un descuento en la nota. Esto incluye c√≥digo sin comentarios o an√°lisis que no sean coherentes con los resultados presentados.\n",
        "   - **Comentarios sin formatear de ChatGPT o herramientas similares ser√°n penalizados (e.g: \"Inserta tu modelo ac√°\", etc.)**\n",
        "\n",
        "<center>\n",
        "<img src=\"https://media1.giphy.com/media/ZkIUY6LZJMwrSMQMWu/giphy.gif?cid=6c09b952msc755426bpsadn4sysofcpqczczi7x1pghd41sw&ep=v1_internal_gif_by_id&rid=giphy.gif&ct=v\" width=\"400\" height=\"300\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "73dd6ad576224431b010e7650d06156e",
        "deepnote_app_block_visible": true,
        "deepnote_cell_type": "markdown",
        "id": "mMwIvE7AimJK"
      },
      "source": [
        "# üì¨ Entrega Parcial 3 (30% del Proyecto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S9iswjPnxmu"
      },
      "source": [
        "## üìñ Enunciado\n",
        "\n",
        "Despu√©s de haber superado con √©xito la implementaci√≥n de sus flujos de trabajo con `Airflow`, el equipo **Deep Drinkers ü§ñ** ha demostrado que no solo sabe construir modelos, sino tambi√©n integrarlos en pipelines reales listos para producci√≥n.\n",
        "\n",
        "El equipo t√©cnico de **SodAI Drinks ü•§** ha quedado tan satisfecho con la automatizaci√≥n de sus procesos que ahora les ha encomendado una nueva, y final, misi√≥n:  \n",
        "- üìä **Evaluar la calidad real de sus modelos en un entorno m√°s desafiante** \n",
        "- üß† **Comunicar los hallazgos de forma clara y profesional frente a una comisi√≥n**.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://i.giphy.com/btbUGSHh3f6eBjbDfh.webp\" width=\"350\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìå Predicciones\n",
        "<center>\n",
        "<img src=\"https://i.giphy.com/NTMxntb8rMzmbd1x97.webp\" width=\"500\" height=\"300\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "Su *pipeline* automatizado debe demostrar que puede manejar datos reales en producci√≥n. **SodAI Drinks** ü•§ liberar√° *batches* de datos en fechas diferentes para evaluar si su sistema se adapta correctamente, los cuales simular√°n la llegada de informaci√≥n nueva (cada batch es una semana).\n",
        "\n",
        "Lo que debe funcionar autom√°ticamente:\n",
        "- **Ejecuci√≥n Automatizada**: Su DAG de `Airflow` debe ser capaz de procesar cada *batch* de datos de manera autom√°tica cuando est√© disponible.\n",
        "- **Monitoreo Continuo**: El *pipeline* debe evaluar la calidad de los datos entrantes y detectar posibles desviaciones respecto al conjunto original.\n",
        "- **Decisi√≥n de Reentrenamiento**: Bas√°ndose en los an√°lisis de *data drift* y m√©tricas de rendimiento, el sistema debe determinar autom√°ticamente si es necesario reentrenar el modelo.\n",
        "- **Tracking Completo**: Todas las ejecuciones, m√©tricas y decisiones deben quedar registradas en `MLFlow` para posterior an√°lisis.\n",
        "- **Generaci√≥n de Predicciones**: Para cada *batch* procesado, el sistema debe generar las predicciones correspondientes y almacenarlas de manera organizada.\n",
        "\n",
        "**IMPORTANTE: Es imperativo que guarden los resultados de su pipeline (m√©tricas, tracking, predicciones, etc) para su an√°lisis en la siguiente secci√≥n.**\n",
        "\n",
        "### üìåEntregable: Competencia en CodaLab\n",
        "\n",
        "<center>\n",
        "<img src=\"https://i.giphy.com/NomCzPIGoXs3EIq77v.webp\" width=\"300\" height=\"300\">\n",
        "</center>\n",
        "\n",
        "Como parte de esta entrega final, el equipo debe utilizar su pipeline entrenado para **generar predicciones en los nuevos conjuntos de datos mencionados anteriormente**.\n",
        "\n",
        "Estas predicciones deben:\n",
        "\n",
        "- Ser generadas directamente desde el *pipeline* previamente desarrollado.  \n",
        "- Guardarse en archivos `.csv` siguiendo el formato requerido.  \n",
        "- Subirse a la plataforma **CodaLab**, donde se realizar√° la evaluaci√≥n final.\n",
        "\n",
        "\n",
        "**IMPORTANTE:** Subir los resultados a tiempo en las tres fechas es **<u>OBLIGATORIO</u>** para la evaluaci√≥n del desempe√±o final del equipo. **Por cada fecha en la que no se suban predicciones, se aplicar√° un descuento de 0.75 puntos (75 d√©cimas) sobre la nota de la Entrega 3.**\n",
        "\n",
        "### üéÅ Bonus [0.5 puntos]\n",
        "\n",
        "Como incentivo adicional, se premiar√° a los **3 equipos con mejor performance en la m√©trica F1** con **0.5 puntos de puntaje adicional** sobre la nota de la Entrega 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìå Informe: Performance del modelo [6.0 puntos]\n",
        "\n",
        "En esta secci√≥n se espera que el equipo analice de manera retrospectiva el performance de su modelo y saque conclusiones en funci√≥n de sus resultados. \n",
        "\n",
        "Para esto, tendr√°n que incurrir en 3 tipos de an√°lisis:\n",
        "\n",
        "- **Individual:** Deben evaluar el performance de su modelo tomando cada semana de forma aislada.\n",
        "\n",
        "- **Comparativo:** Deben evaluar el performance de su modelo *a trav√©s* de las semanas, comparando el desempe√±o entre las semanas e identificando posibles tendencias.\n",
        "    - Para esta parte se espera que generen gr√°ficos de tendencia y tablas comparativas para apoyar su an√°lisis.\n",
        "\n",
        "- **Conclusiones y Aprendizajes:** Deben escribir sus principales conclusiones y aprendizajes de este proyecto. \n",
        "\n",
        "A lo largo de esta secci√≥n, se espera que respondan preguntas como:\n",
        "\n",
        "1. ¬øC√≥mo variaron sus m√©tricas a lo largo de los distintos conjuntos de datos? \n",
        "2. ¬øEn qu√© momento el modelo tuvo su peor desempe√±o y por qu√©?\n",
        "3. ¬øDetectaron alg√∫n cambio significativo (drift) en la distribuci√≥n de los datos? ¬øC√≥mo lo identificaron?  \n",
        "4. ¬øTuvieron que reentrenar su modelo con los nuevos datos? ¬øPorqu√©? ¬øAyud√≥ esto al performance de su modelo?\n",
        "4. ¬øQu√© decisi√≥n t√©cnica (modelo, m√©trica, imputaci√≥n, etc.) tuvo m√°s impacto en los resultados?  \n",
        "5. ¬øQu√© hiperpar√°metro fue el m√°s importante para su modelo? \n",
        "5. ¬øQu√© variable fue m√°s influyente en las predicciones? ¬øC√≥mo lo interpretan? ¬øC√≥mo cambi√≥ su importancia con respecto a las otras variables a lo largo de los batch de datos?\n",
        "6. ¬øQu√© aprendieron sobre el negocio a partir de los resultados del modelo?\n",
        "7. ¬øQu√© limitaciones detectaron en su modelo o en los datos?  \n",
        "\n",
        "**IMPORTANTE: Se espera que en sus respuestas hagan referencia a los artefactos (m√©tricas, hiperpar√°metros, gr√°ficos de interpretabilidad, etc) que su pipeline genera.**\n",
        "\n",
        "<center>\n",
        "<img src=\"https://media1.tenor.com/m/jyQ3SPT1htEAAAAd/i-love-this-performance-even-more-simon-cowell.gif\" width=\"300\" height=\"300\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìå An√°lisis individual [3.0 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "clientes_df = pd.read_parquet('clientes.parquet')\n",
        "productos_df = pd.read_parquet('productos.parquet')\n",
        "\n",
        "universe_size = len(clientes_df) * len(productos_df)\n",
        "\n",
        "def get_batch_performance(batch_id):\n",
        "    # Cargar datos reales\n",
        "    data = pd.read_parquet(f\"data/batch_t{batch_id}.parquet\")\n",
        "    data = data.groupby(['customer_id', 'product_id']).size().reset_index()\n",
        "    true_pairs = set(map(tuple, data[['customer_id', 'product_id']].values))\n",
        "\n",
        "    # Cargar predicciones\n",
        "    preds = pd.read_csv(f\"predictions/batch_t{batch_id}.csv\",\n",
        "                        names=['customer_id', 'product_id'])\n",
        "    pred_pairs = set(map(tuple, preds[['customer_id', 'product_id']].values))\n",
        "\n",
        "    # TP = predicho y real\n",
        "    tp = len(pred_pairs & true_pairs)\n",
        "    # FP = predicho pero no real\n",
        "    fp = len(pred_pairs - true_pairs)\n",
        "    # FN = real pero no predicho\n",
        "    fn = len(true_pairs - pred_pairs)\n",
        "    # TN = universo total - todo lo dem√°s\n",
        "    tn = universe_size - tp - fp - fn\n",
        "\n",
        "    y_true = [1]*tp + [0]*fp + [1]*fn + [0]*tn\n",
        "    y_pred = [1]*tp + [1]*fp + [0]*fn + [0]*tn\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"precision\": precision_score(y_true, y_pred),\n",
        "        \"recall\": recall_score(y_true, y_pred),\n",
        "        \"f1\": f1_score(y_true, y_pred)\n",
        "    }\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### üìå Batch 1 (01/01/25 - 05/01/25) [0.75 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# aqu√≠ el c√≥digo \n",
        "# concatenar el batch 1 a los datos historicos para reentrenar y obtener modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El modelo gener√≥ 100 000 sugerencias para X posibles pares cliente‚Äìproducto. Al compararlas con las compras efectivas se registraron Y verdaderos positivos, Z falsos positivos y W falsos negativos. Con estos valores, la cobertura alcanza 0,85, lo que indica que el sistema recupera la mayor parte de las compras reales. Sin embargo, emite casi 57 recomendaciones por cada interacci√≥n verdadera, lo que explica la baja precisi√≥n general (~0,03).\n",
        "\n",
        "El an√°lisis por cliente revela que m√°s del X % presenta precisi√≥n igual a cero y que menos del Y % supera 0,10. Esto muestra que el modelo funciona bien para un grupo reducido, pero para la mayor√≠a sus aciertos son pr√°cticamente aleatorios.\n",
        "\n",
        "En una muestra de 50 clientes se observa que reciben entre 30 y 85 recomendaciones, mientras que como m√°ximo compran unos 17 productos. Esta diferencia confirma que utilizar cualquier probabilidad mayor que cero como criterio resulta demasiado permisivo y genera un exceso de sugerencias sin relevancia.\n",
        "\n",
        "Al limitar el an√°lisis a las primeras X predicciones, la precisi√≥n subi√≥ de 0,X a 0,Y y el F1 se duplic√≥, manteniendo un recall de 1,0. Este comportamiento indica que aplicar un umbral m√°s exigente ‚Äîo un top-N por cliente‚Äî podr√≠a mejorar de forma importante la precisi√≥n sin perder capacidad de cobertura.\n",
        "\n",
        "Desde una perspectiva operativa, emitir N recomendaciones por cada compra real no es viable, pues puede saturar al cliente. Ajustar el umbral de decisi√≥n aparece como la medida m√°s inmediata y efectiva; incluso reducciones dr√°sticas en el n√∫mero de predicciones mantendr√≠an buenos niveles de cobertura. Adem√°s, la variabilidad en la precisi√≥n sugiere considerar estrategias segmentadas o filtros que limiten la cantidad de sugerencias que recibe cada usuario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### üìå Batch 2 (06/01/25 - 12/01/25) [0.75 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# aqu√≠ el c√≥digo \n",
        "# concatenar el batch 2 a los datos historicos para reentrenar y obtener modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El segundo batch contiene 5 103 interacciones reales entre cliente y producto. El sistema gener√≥ 161 413 recomendaciones y obtuvo X TP, Y FP y Z FN. Con estos valores, el recall sube a R, unos cinco puntos m√°s que en el batch 1. La tasa de predicciones se mantiene igual: alrededor de S sugerencias por cada caso real.\n",
        "\n",
        "La precisi√≥n por cliente sigue concentr√°ndose en valores muy bajos, aunque aparece un peque√±o aumento de usuarios con precisiones entre P‚ÇÅ y P‚ÇÇ. En la muestra de N clientes se vuelve a observar un fuerte desbalance: entre X y Y recomendaciones por cliente frente a un m√°ximo de A compras reales.\n",
        "\n",
        "Al limitar la evaluaci√≥n a las primeras A predicciones, la precisi√≥n sube a P‚ÇÉ y el F1 llega a F, manteniendo un recall perfecto. El efecto es a√∫n m√°s claro que en el batch 1 y demuestra que reducir de forma dr√°stica el volumen de sugerencias mejora de manera notable la precisi√≥n sin perder cobertura.\n",
        "\n",
        "En comparaci√≥n con la semana previa, el modelo incrementa los TP gracias al mayor historial, pero los FP crecen en proporci√≥n similar, lo que confirma que a√∫n no filtra adecuadamente los casos negativos. La mejora obtenida con el recorte de predicciones tambi√©n es mucho mayor en este batch.\n",
        "\n",
        "A nivel operativo, el riesgo de saturar a los clientes persiste, por lo que el ajuste del umbral sigue siendo una medida urgente. El aumento de recall respalda el reentrenamiento continuo, y se recomienda limitar la cantidad de productos sugeridos por cliente ‚Äîpor ejemplo, un top-K‚Äî antes de entregar las recomendaciones. Se mantienen las conclusiones del batch 1, pero se evidencia que el modelo aprovecha la nueva informaci√≥n a medida que avanza el tiempo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### üìå Batch 03 (13/01/25 - 19/01/25) [0.75 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# aqu√≠ el c√≥digo \n",
        "# concatenar el batch 3 a los datos historicos para reentrenar y obtener modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En la tercera semana se registraron 4 922 compras reales. El modelo gener√≥ 153 033 recomendaciones y obtuvo X TP, Y FP y Z FN. El recall cae a R, cuatro puntos menos que en el Batch 2, y la tasa de predicciones baja apenas a T, manteni√©ndose en niveles similares a semanas anteriores.\n",
        "\n",
        "La precisi√≥n por cliente sigue siendo muy baja: la mayor√≠a permanece por debajo de P‚ÇÅ y solo unos pocos llegan a P‚ÇÇ‚ÄìP‚ÇÉ. En la muestra de 50 clientes se repite el desbalance: X‚ÄìY productos recomendados por persona frente a un m√°ximo de N‚ÄìM compras reales.\n",
        "\n",
        "Al limitar la salida a R recomendaciones, la precisi√≥n vuelve a P‚ÇÑ y el F1 a F, con recall perfecto. El comportamiento es casi id√©ntico al de Batch 2, confirmando que un recorte fuerte mejora notablemente la calidad sin perder cobertura.\n",
        "\n",
        "La comparaci√≥n semana a semana muestra un recall fluctuante y una tasa de predicciones pr√°cticamente constante. Las m√©tricas ‚Äúrecortadas‚Äù se estabilizan entre Batch 2 y Batch 3, lo que indica que un top-N o umbral fijo podr√≠a funcionar bien.\n",
        "\n",
        "Operativamente, el modelo sigue generando demasiadas recomendaciones y el reentrenamiento no siempre se traduce en mejor cobertura. Se refuerza la necesidad de aplicar un filtro en inferencia (por ejemplo, un top-K) y revisar el proceso de actualizaci√≥n del modelo para evitar variaciones semanales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### üìå Batch 04 (20/01/25 - 26/01/25) [0.75 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# aqu√≠ el c√≥digo \n",
        "# concatenar el batch 4 a los datos historicos para reentrenar y obtener modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El cuarto batch incluye 4 866 compras reales. El modelo gener√≥ 122 494 recomendaciones y obtuvo X TP, Y FP y Z FN. El recall baja a R, el valor m√°s bajo de las cuatro semanas, y la tasa de predicciones cae por primera vez de forma clara a T, producto de emitir alrededor de X mil sugerencias en lugar de las ~Y mil anteriores.\n",
        "\n",
        "La precisi√≥n por cliente sigue siendo muy baja, aunque aparece un leve desplazamiento hacia mejores valores: aumenta el grupo con precisiones entre P‚ÇÅ y P‚ÇÇ, en l√≠nea con la ligera mejora global (P‚ÇÉ). En la muestra de 50 clientes se mantiene un fuerte desbalance: 60‚Äì110 productos recomendados frente a un m√°ximo de 15 compras reales.\n",
        "\n",
        "Al recortar las recomendaciones a las primeras R, la precisi√≥n vuelve a P‚ÇÑ y el F1 a F, con recall perfecto. Este comportamiento coincide con Batches 2 y 3 y muestra que el umbral impl√≠cito es bastante estable.\n",
        "\n",
        "En la comparaci√≥n global, el recall fluct√∫a entre R‚ÇÅ y R‚ÇÇ y la tasa de predicciones reci√©n en este Batch desciende de manera relevante. Aun as√≠, siguen gener√°ndose unas 25 sugerencias por cada caso real. La estabilidad de los resultados ‚Äúrecortados‚Äù indica que un umbral fijo podr√≠a sostener un F1 cercano a F‚ÇÇ de forma consistente.\n",
        "\n",
        "Operativamente, la ca√≠da simult√°nea en recall y volumen de recomendaciones muestra que cualquier filtrado implica sacrificar parte de la cobertura y debe equilibrarse seg√∫n el objetivo del negocio. La precisi√≥n contin√∫a siendo demasiado baja para producci√≥n, por lo que un top-K o un umbral alto (percentil 98‚Äì99) permitir√≠a acercarse al rango de ~R recomendaciones con un nivel de F1 aceptable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìå An√°lisis comparativo [2.0 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aqu√≠ se espera que puedan generar gr√°ficos para ver como fue la evoluci√≥n de las m√©tricas a lo largo de las semanas/batches \n",
        "# En caso de que corrieron todos los modelos con Optuna y SHAP pueden adjuntar los gr√°ficos como\n",
        "# - Optimization History Plot\n",
        "# - Importance Plot\n",
        "# - SHAP Summary Plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Conclusiones**\n",
        "\n",
        "El sistema muestra un comportamiento dual. Por un lado, alcanza una cobertura....."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. ¬øC√≥mo variaron sus m√©tricas a lo largo de los distintos conjuntos de datos? \n",
        "\n",
        "* Comparar comportamiento sin filtro vs con Top-N\n",
        "* Analizar trade-off entre precisi√≥n/F1 y recall\n",
        "* Identificar estabilidad del sistema y rol del umbral en el balance calidad-cobertura\n",
        "\n",
        "\n",
        "2. ¬øEn qu√© momento el modelo tuvo su peor desempe√±o y por qu√©?\n",
        "\n",
        "* Identificar batch con peor rendimiento\n",
        "* Explicar causas: falta de historial, calibraci√≥n de probabilidades\n",
        "* Mencionar mejora progresiva con acumulaci√≥n de datos\n",
        "\n",
        "3. ¬øDetectaron alg√∫n cambio significativo (drift) en la distribuci√≥n de los datos? ¬øC√≥mo lo identificaron? \n",
        "\n",
        "* Describir metodolog√≠a de detecci√≥n (tests estad√≠sticos para variables num√©ricas y categ√≥ricas, KS chi-cuadrado)\n",
        "* Explicar sistema de scoring y umbral de activaci√≥n\n",
        "* Analizar si el drift detectado fue real o producto de sensibilidad del detector\n",
        "* Discutir posibles causas: historial limitado, umbral muy bajo\n",
        "\n",
        "4. ¬øTuvieron que reentrenar su modelo con los nuevos datos? ¬øPorqu√©? ¬øAyud√≥ esto al performance de su modelo?\n",
        "\n",
        "* Mencionar frecuencia de reentrenamiento y raz√≥n (activaci√≥n por drift)\n",
        "* Analizar impacto diferenciado: mejora en cobertura vs estancamiento en precisi√≥n\n",
        "* Explicar por qu√© mejor√≥ una m√©trica pero no la otra (relaci√≥n con umbral de decisi√≥n)\n",
        "* Conclusi√≥n sobre trade-off cobertura-relevancia\n",
        "\n",
        "5. ¬øQu√© decisi√≥n t√©cnica (modelo, m√©trica, imputaci√≥n, etc.) tuvo m√°s impacto en los resultados?  \n",
        "\n",
        "* Identificar decisi√≥n con mayor impacto positivo (feature engineering)\n",
        "* Especificar tipos de variables creadas (recencia, agregaciones temporales)\n",
        "* Identificar decisi√≥n con mayor impacto negativo (pol√≠tica de umbral)\n",
        "* Explicar c√≥mo afect√≥ cada decisi√≥n al desempe√±o final\n",
        "\n",
        "6. ¬øQu√© hiperpar√°metro fue el m√°s importante para su modelo?\n",
        "\n",
        "* Mencionar herramienta de optimizaci√≥n utilizada\n",
        "* Listar hiperpar√°metros m√°s influyentes identificados\n",
        "* Explicar rol de cada uno: manejo de desbalance, regularizaci√≥n, captura de interacciones\n",
        "* Conectar ajuste de hiperpar√°metros con m√©trica final alcanzada\n",
        "\n",
        "\n",
        "7. ¬øQu√© variable fue m√°s influyente en las predicciones? ¬øC√≥mo lo interpretan? ¬øC√≥mo cambi√≥ su importancia con respecto a las otras variables a lo largo de los batch de datos?\n",
        "\n",
        "Los feature importances de los cuatro modelos XGBoost muestran que el modelo depende casi por completo de la recencia de compra. Las variables m√°s influyentes fueron:\n",
        "\n",
        " - num__items_roll4_mean \n",
        "\n",
        "- num__items_last_week\n",
        "\n",
        "- cat__sub_category_GASEOSAS\n",
        "\n",
        "- cat__week_1\n",
        "\n",
        "- cat__brand_Brand 24\n",
        "\n",
        "Las m√°s consistentes en todos los batches fueron:\n",
        "\n",
        "- num__items_roll4_mean\n",
        "- num__items_last_week\n",
        "- cat__week_1 \n",
        "- cat__brand_Brand 24\n",
        "\n",
        "\n",
        "- num__items_roll4_mean fue la variable dominante en todos los batches (35‚Äì48% del gain), aunque baj√≥ ligeramente del Batch 1 al 4.\n",
        "- num__items_last_week tambi√©n se mantuvo estable en el Top 5, con una leve ca√≠da en su aporte.\n",
        "Entre las categ√≥ricas, cat__sub_category_GASEOSAS gan√≥ relevancia en los batches intermedios, especialmente en el Batch 3.\n",
        "\n",
        "En conjunto, las variables de recencia siguieron siendo las m√°s predictivas, pero su descenso marginal indica que el modelo empez√≥ a incorporar se√±ales adicionales como categor√≠as, marcas y patr√≥n semanal.\n",
        "\n",
        "\n",
        "8. ¬øQu√© aprendieron sobre el negocio a partir de los resultados del modelo?\n",
        "\n",
        "* Ac√° ver patrones de comportamiento como importancia de compras recientes, estacionalidad\n",
        "* Diferencias por categor√≠a/marca (segmentacion)\n",
        "* Comentar performance, balance cobertura-relevancia, volumen de recomendaciones\n",
        "* Consistencia de variables clave en el tiempo\n",
        "* Algunas recomendacoinse estrategias para mejorar eficiencia (filtros, l√≠mites, personalizaci√≥n)\n",
        "\n",
        "9. ¬øQu√© limitaciones detectaron en su modelo o en los datos?\n",
        "\n",
        "* Por ej el volumen excesivo de recomendaciones y su impacto, proporci√≥n de positivos y consecuencias del submuestreo, problemas con la estrategia de split temporal y optimismo en m√©tricas, sugerencias de mejoras en nuestro caso un esquema de evaluaci√≥n m√°s realista"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìå Conclusiones y Aprendizajes [1.0 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Este proyecto permiti√≥ ...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìÅ Estructura de entrega\n",
        "\n",
        "Se espera que su entrega cuente con la siguiente estructura de carpetas:\n",
        "\n",
        "```bash\n",
        "entrega_3/\n",
        "‚îÇ\n",
        "‚îú‚îÄ‚îÄ informe.ipynb # Jupyter notebook con sus resultados\n",
        "‚îÇ\n",
        "‚îú‚îÄ‚îÄ predictions/ # Carpeta con las predicciones para cada batch de datos\n",
        "‚îÇ\n",
        "‚îî‚îÄ‚îÄ data/ # Carpeta con los datos realizados (lo que realmente ocurri√≥)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM6rrqJ85tmz"
      },
      "source": [
        "Mucho √©xito!\n",
        "\n",
        "<center>\n",
        "<img src=\"https://gifdb.com/images/high/may-the-force-be-with-you-anakin-skywalker-n2g5o0pm4h6iylsx.gif\" width=\"400\" height=\"300\">\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "deepnote_app_layout": "powerful-article",
    "deepnote_app_reactivity_enabled": true,
    "deepnote_notebook_id": "2939a76dd7c14f7f948714e40aa8bd20",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
