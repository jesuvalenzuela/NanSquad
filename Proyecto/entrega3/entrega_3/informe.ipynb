{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "516acf1d6e9d4ddb9a8acdeb6b1cca14",
        "deepnote_app_block_visible": true,
        "deepnote_cell_type": "markdown",
        "id": "-MGJGjPDimJI"
      },
      "source": [
        "![](https://www.dii.uchile.cl/wp-content/uploads/2021/06/Magi%CC%81ster-en-Ciencia-de-Datos.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "befdb70375f04ab79952117eb63723e7",
        "deepnote_app_block_visible": true,
        "deepnote_cell_type": "markdown",
        "id": "SN4W-_BNimJJ"
      },
      "source": [
        "**MDS7202: Laboratorio de ProgramaciÃ³n CientÃ­fica para Ciencia de Datos**\n",
        "\n",
        "### ğŸ‘¨â€ğŸ«ğŸ‘©â€ğŸ« Cuerpo Docente:\n",
        "\n",
        "- Profesores: Diego Cortez, Gabriel Iturra\n",
        "- Auxiliares: Melanie PeÃ±a, Valentina Rojas\n",
        "- Ayudantes: NicolÃ¡s Cabello, Cristopher Urbina\n",
        "\n",
        "### ğŸ‘¨â€ğŸ’»ğŸ‘©â€ğŸ’» Estudiantes:\n",
        "- Estudiante nÂ°1:\n",
        "- Estudiante nÂ°2:\n",
        "\n",
        "_Por favor, lean detalladamente las instrucciones de la tarea antes de empezar a escribir._\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GjshSnpjGcr"
      },
      "source": [
        "### **Instrucciones importantes**\n",
        "\n",
        "1. **Formato del informe**:  \n",
        "   - El informe debe estar integrado dentro de un **Jupyter Notebook**. No es necesario subirlo a una plataforma externa, pero debe cumplir con los siguientes requisitos:  \n",
        "     - Estructura clara y ordenada.  \n",
        "     - CÃ³digo acompaÃ±ado de explicaciones detalladas.  \n",
        "     - Resultados presentados de forma visual y analÃ­tica.  \n",
        "\n",
        "2. **Descuento por informes deficientes**:  \n",
        "   - Cualquier secciÃ³n del informe que no tenga una explicaciÃ³n adecuada o no respete el formato serÃ¡ penalizada con un descuento en la nota. Esto incluye cÃ³digo sin comentarios o anÃ¡lisis que no sean coherentes con los resultados presentados.\n",
        "   - **Comentarios sin formatear de ChatGPT o herramientas similares serÃ¡n penalizados (e.g: \"Inserta tu modelo acÃ¡\", etc.)**\n",
        "\n",
        "<center>\n",
        "<img src=\"https://media1.giphy.com/media/ZkIUY6LZJMwrSMQMWu/giphy.gif?cid=6c09b952msc755426bpsadn4sysofcpqczczi7x1pghd41sw&ep=v1_internal_gif_by_id&rid=giphy.gif&ct=v\" width=\"400\" height=\"300\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "73dd6ad576224431b010e7650d06156e",
        "deepnote_app_block_visible": true,
        "deepnote_cell_type": "markdown",
        "id": "mMwIvE7AimJK"
      },
      "source": [
        "# ğŸ“¬ Entrega Parcial 3 (30% del Proyecto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbrEry-nnsfs"
      },
      "source": [
        "### ğŸ“ª Fecha de Entrega: \n",
        "\n",
        "Esta entrega cuenta con 2 partes:\n",
        "\n",
        "- **Predicciones**: 1 de Diciembre, 2 de Diciembre, 3 de Diciembre, 4 de Diciembre\n",
        "- **Informe:** 8 de Diciembre."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S9iswjPnxmu"
      },
      "source": [
        "## ğŸ“– Enunciado\n",
        "\n",
        "DespuÃ©s de haber superado con Ã©xito la implementaciÃ³n de sus flujos de trabajo con `Airflow`, el equipo **Deep Drinkers ğŸ¤–** ha demostrado que no solo sabe construir modelos, sino tambiÃ©n integrarlos en pipelines reales listos para producciÃ³n.\n",
        "\n",
        "El equipo tÃ©cnico de **SodAI Drinks ğŸ¥¤** ha quedado tan satisfecho con la automatizaciÃ³n de sus procesos que ahora les ha encomendado una nueva, y final, misiÃ³n:  \n",
        "- ğŸ“Š **Evaluar la calidad real de sus modelos en un entorno mÃ¡s desafiante** \n",
        "- ğŸ§  **Comunicar los hallazgos de forma clara y profesional frente a una comisiÃ³n**.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://i.giphy.com/btbUGSHh3f6eBjbDfh.webp\" width=\"350\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Œ Predicciones\n",
        "<center>\n",
        "<img src=\"https://i.giphy.com/NTMxntb8rMzmbd1x97.webp\" width=\"500\" height=\"300\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "Su *pipeline* automatizado debe demostrar que puede manejar datos reales en producciÃ³n. **SodAI Drinks** ğŸ¥¤ liberarÃ¡ *batches* de datos en fechas diferentes para evaluar si su sistema se adapta correctamente, los cuales simularÃ¡n la llegada de informaciÃ³n nueva (cada batch es una semana).\n",
        "\n",
        "Lo que debe funcionar automÃ¡ticamente:\n",
        "- **EjecuciÃ³n Automatizada**: Su DAG de `Airflow` debe ser capaz de procesar cada *batch* de datos de manera automÃ¡tica cuando estÃ© disponible.\n",
        "- **Monitoreo Continuo**: El *pipeline* debe evaluar la calidad de los datos entrantes y detectar posibles desviaciones respecto al conjunto original.\n",
        "- **DecisiÃ³n de Reentrenamiento**: BasÃ¡ndose en los anÃ¡lisis de *data drift* y mÃ©tricas de rendimiento, el sistema debe determinar automÃ¡ticamente si es necesario reentrenar el modelo.\n",
        "- **Tracking Completo**: Todas las ejecuciones, mÃ©tricas y decisiones deben quedar registradas en `MLFlow` para posterior anÃ¡lisis.\n",
        "- **GeneraciÃ³n de Predicciones**: Para cada *batch* procesado, el sistema debe generar las predicciones correspondientes y almacenarlas de manera organizada.\n",
        "\n",
        "**IMPORTANTE: Es imperativo que guarden los resultados de su pipeline (mÃ©tricas, tracking, predicciones, etc) para su anÃ¡lisis en la siguiente secciÃ³n.**\n",
        "\n",
        "### ğŸ“ŒEntregable: Competencia en CodaLab\n",
        "\n",
        "<center>\n",
        "<img src=\"https://i.giphy.com/NomCzPIGoXs3EIq77v.webp\" width=\"300\" height=\"300\">\n",
        "</center>\n",
        "\n",
        "Como parte de esta entrega final, el equipo debe utilizar su pipeline entrenado para **generar predicciones en los nuevos conjuntos de datos mencionados anteriormente**.\n",
        "\n",
        "Estas predicciones deben:\n",
        "\n",
        "- Ser generadas directamente desde el *pipeline* previamente desarrollado.  \n",
        "- Guardarse en archivos `.csv` siguiendo el formato requerido.  \n",
        "- Subirse a la plataforma **CodaLab**, donde se realizarÃ¡ la evaluaciÃ³n final.\n",
        "\n",
        "En CodaLab podrÃ¡n:\n",
        "\n",
        "- Ver el rendimiento de su modelo frente a los de otros equipos.  \n",
        "- Obtener una puntuaciÃ³n basada en la mÃ©trica definida del proyecto.  \n",
        "\n",
        "Cada set de predicciones debe ser publicado en CodaLab en las siguientes fechas:\n",
        "- **Predicciones 1 ğŸ“…** : 1 de Diciembre (Fecha de predicciÃ³n: 01/01/25 - 05/01/25)\n",
        "    - Note que para este set de predicciones, sÃ³lo tendrÃ¡n acceso a los datos publicados en la Entrega 1.\n",
        "- **Predicciones 2 ğŸ“…** : 2 de Diciembre (Fecha de predicciÃ³n: 06/01/25 - 12/01/25)\n",
        "- **Predicciones 3 ğŸ“…** : 3 de Diciembre (Fecha de predicciÃ³n: 13/01/25 - 19/01/25)\n",
        "- **Predicciones 4 ğŸ“…** : 4 de Diciembre (Fecha de predicciÃ³n: 20/01/25 - 26/01/25)\n",
        "\n",
        "Para simular la llegada de nuevos datos, se publicarÃ¡n los siguientes conjuntos de datos:\n",
        "- **Batch 1 ğŸ“…** : 2 de Diciembre (Con datos realizados del perÃ­odo 01/01/25 - 05/01/25)\n",
        "- **Batch 2 ğŸ“…** : 3 de Diciembre (Con datos realizados del perÃ­odo 06/01/25 - 12/01/25)\n",
        "- **Batch 3 ğŸ“…** : 4 de Diciembre (Con datos realizados del perÃ­odo 13/01/25 - 19/01/25)\n",
        "- **Batch 4 ğŸ“…** : 5 de Diciembre (Con datos realizados del perÃ­odo 20/01/25 - 26/01/25)\n",
        "    - Note como este conjunto de datos se publica **despuÃ©s** de la competencia, por lo que sÃ³lo les servirÃ¡ para la Ãºltima evaluaciÃ³n requerida en el informe.\n",
        "\n",
        "**IMPORTANTE:** Subir los resultados a tiempo en las tres fechas es **<u>OBLIGATORIO</u>** para la evaluaciÃ³n del desempeÃ±o final del equipo. **Por cada fecha en la que no se suban predicciones, se aplicarÃ¡ un descuento de 0.75 puntos (75 dÃ©cimas) sobre la nota de la Entrega 3.**\n",
        "\n",
        "### ğŸ Bonus [0.5 puntos]\n",
        "\n",
        "Como incentivo adicional, se premiarÃ¡ a los **3 equipos con mejor performance en la mÃ©trica F1** con **0.5 puntos de puntaje adicional** sobre la nota de la Entrega 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Œ Informe: Performance del modelo [6.0 puntos]\n",
        "\n",
        "En esta secciÃ³n se espera que el equipo analice de manera retrospectiva el performance de su modelo y saque conclusiones en funciÃ³n de sus resultados. \n",
        "\n",
        "Para esto, tendrÃ¡n que incurrir en 3 tipos de anÃ¡lisis:\n",
        "\n",
        "- **Individual:** Deben evaluar el performance de su modelo tomando cada semana de forma aislada.\n",
        "\n",
        "- **Comparativo:** Deben evaluar el performance de su modelo *a travÃ©s* de las semanas, comparando el desempeÃ±o entre las semanas e identificando posibles tendencias.\n",
        "    - Para esta parte se espera que generen grÃ¡ficos de tendencia y tablas comparativas para apoyar su anÃ¡lisis.\n",
        "\n",
        "- **Conclusiones y Aprendizajes:** Deben escribir sus principales conclusiones y aprendizajes de este proyecto. \n",
        "\n",
        "A lo largo de esta secciÃ³n, se espera que respondan preguntas como:\n",
        "\n",
        "1. Â¿CÃ³mo variaron sus mÃ©tricas a lo largo de los distintos conjuntos de datos? \n",
        "2. Â¿En quÃ© momento el modelo tuvo su peor desempeÃ±o y por quÃ©?\n",
        "3. Â¿Detectaron algÃºn cambio significativo (drift) en la distribuciÃ³n de los datos? Â¿CÃ³mo lo identificaron?  \n",
        "4. Â¿Tuvieron que reentrenar su modelo con los nuevos datos? Â¿PorquÃ©? Â¿AyudÃ³ esto al performance de su modelo?\n",
        "4. Â¿QuÃ© decisiÃ³n tÃ©cnica (modelo, mÃ©trica, imputaciÃ³n, etc.) tuvo mÃ¡s impacto en los resultados?  \n",
        "5. Â¿QuÃ© hiperparÃ¡metro fue el mÃ¡s importante para su modelo? \n",
        "5. Â¿QuÃ© variable fue mÃ¡s influyente en las predicciones? Â¿CÃ³mo lo interpretan? Â¿CÃ³mo cambiÃ³ su importancia con respecto a las otras variables a lo largo de los batch de datos?\n",
        "6. Â¿QuÃ© aprendieron sobre el negocio a partir de los resultados del modelo?\n",
        "7. Â¿QuÃ© limitaciones detectaron en su modelo o en los datos?  \n",
        "\n",
        "**IMPORTANTE: Se espera que en sus respuestas hagan referencia a los artefactos (mÃ©tricas, hiperparÃ¡metros, grÃ¡ficos de interpretabilidad, etc) que su pipeline genera.**\n",
        "\n",
        "<center>\n",
        "<img src=\"https://media1.tenor.com/m/jyQ3SPT1htEAAAAd/i-love-this-performance-even-more-simon-cowell.gif\" width=\"300\" height=\"300\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ“Œ AnÃ¡lisis individual [3.0 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "clientes_df = pd.read_parquet('clientes.parquet')\n",
        "productos_df = pd.read_parquet('productos.parquet')\n",
        "\n",
        "universe_size = len(clientes_df) * len(productos_df)\n",
        "\n",
        "\n",
        "def load_data(batch_id):\n",
        "    # Cargar datos reales\n",
        "    data = pd.read_parquet(f\"data/batch_t{batch_id}.parquet\")\n",
        "    data = data.groupby(['customer_id', 'product_id']).size().reset_index()\n",
        "\n",
        "    preds = pd.read_csv(f\"predictions/batch_t{batch_id}.csv\",\n",
        "                        names=['customer_id', 'product_id'])\n",
        "    \n",
        "    return data, preds\n",
        "\n",
        "def get_batch_performance(data, preds):\n",
        "    true_pairs = set(map(tuple, data[['customer_id', 'product_id']].values))\n",
        "    print(f\"cantidad real: {len(true_pairs)}\")\n",
        "\n",
        "    # Cargar predicciones\n",
        "    pred_pairs = set(map(tuple, preds[['customer_id', 'product_id']].values))\n",
        "    print(f\"cantidad predicha: {len(pred_pairs)}\")\n",
        "\n",
        "    # === MÃ©tricas globales ===\n",
        "    # TP = predicho y real\n",
        "    tp = len(pred_pairs & true_pairs)\n",
        "    print(f\"TP: {tp}\")\n",
        "\n",
        "    # FP = predicho pero no real\n",
        "    fp = len(pred_pairs - true_pairs)\n",
        "    print(f\"FP: {fp}\")\n",
        "\n",
        "    # FN = real pero no predicho\n",
        "    fn = len(true_pairs - pred_pairs)\n",
        "    print(f\"FN: {fn}\")\n",
        "\n",
        "    # TN = universo total - todo lo demÃ¡s\n",
        "    tn = universe_size - tp - fp - fn\n",
        "    print(f\"TN: {tn}\")\n",
        "\n",
        "    y_true = [1]*tp + [0]*fp + [1]*fn + [0]*tn\n",
        "    y_pred = [1]*tp + [1]*fp + [0]*fn + [0]*tn\n",
        "\n",
        "    global_metrics = {\n",
        "        \"accuracy\": round(accuracy_score(y_true, y_pred),2),\n",
        "        \"precision\": round(precision_score(y_true, y_pred),2),\n",
        "        \"recall\": round(recall_score(y_true, y_pred),2),\n",
        "        \"f1\": round(f1_score(y_true, y_pred),2)\n",
        "    }\n",
        "\n",
        "    return global_metrics\n",
        "\n",
        "def analyze_by_customer(data, preds):\n",
        "    \"\"\"Calcula precisiÃ³n por cliente\"\"\"\n",
        "    \n",
        "    # Agrupar datos reales por cliente\n",
        "    true_by_customer = data.groupby('customer_id')['product_id'].apply(set).to_dict()\n",
        "    \n",
        "    # Agrupar predicciones por cliente\n",
        "    pred_by_customer = preds.groupby('customer_id')['product_id'].apply(set).to_dict()\n",
        "    \n",
        "    # Calcular mÃ©tricas por cliente\n",
        "    customer_data = []\n",
        "    \n",
        "    for customer_id in pred_by_customer.keys():\n",
        "        pred_products = pred_by_customer.get(customer_id, set())\n",
        "        true_products = true_by_customer.get(customer_id, set())\n",
        "        \n",
        "        tp = len(pred_products & true_products)\n",
        "        fp = len(pred_products - true_products)\n",
        "        \n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        \n",
        "        customer_data.append({\n",
        "            'customer_id': customer_id,\n",
        "            'tp': tp,\n",
        "            'fp': fp,\n",
        "            'precision': precision,\n",
        "            'total_predictions': len(pred_products)\n",
        "        })\n",
        "    \n",
        "    customer_df = pd.DataFrame(customer_data)\n",
        "    \n",
        "    # Calcular X e Y\n",
        "    total_customers = len(customer_df)\n",
        "    customers_zero_precision = (customer_df['precision'] == 0).sum()\n",
        "    customers_above_010 = (customer_df['precision'] > 0.10).sum()\n",
        "    \n",
        "    X = (customers_zero_precision / total_customers) * 100\n",
        "    Y = (customers_above_010 / total_customers) * 100\n",
        "    \n",
        "    print(f\"\\n=== AnÃ¡lisis por Cliente ===\")\n",
        "    print(f\"Total clientes con predicciones: {total_customers}\")\n",
        "    print(f\"Clientes con precisiÃ³n = 0: {customers_zero_precision} ({X:.2f}%)\")\n",
        "    print(f\"Clientes con precisiÃ³n > 0.10: {customers_above_010} ({Y:.2f}%)\")\n",
        "    \n",
        "    return customer_df\n",
        "\n",
        "\n",
        "def analyze_sample_customers(data, preds, sample_size=50):\n",
        "    \"\"\"Analiza una muestra de clientes para entender recomendaciones vs compras reales\"\"\"\n",
        "    \n",
        "    # Agrupar datos reales por cliente (compras reales)\n",
        "    true_by_customer = data.groupby('customer_id')['product_id'].apply(set).to_dict()\n",
        "    \n",
        "    # Agrupar predicciones por cliente (recomendaciones)\n",
        "    pred_by_customer = preds.groupby('customer_id')['product_id'].apply(set).to_dict()\n",
        "    \n",
        "    # Obtener clientes que tienen predicciones\n",
        "    customers_with_preds = list(pred_by_customer.keys())\n",
        "    \n",
        "    # Tomar muestra aleatoria\n",
        "    import random\n",
        "    sample_customers = random.sample(customers_with_preds, min(sample_size, len(customers_with_preds)))\n",
        "    \n",
        "    sample_data = []\n",
        "    for customer_id in sample_customers:\n",
        "        num_recommendations = len(pred_by_customer.get(customer_id, set()))\n",
        "        num_real_purchases = len(true_by_customer.get(customer_id, set()))\n",
        "        \n",
        "        sample_data.append({\n",
        "            'customer_id': customer_id,\n",
        "            'num_recommendations': num_recommendations,\n",
        "            'num_real_purchases': num_real_purchases\n",
        "        })\n",
        "    \n",
        "    sample_df = pd.DataFrame(sample_data)\n",
        "    \n",
        "    # Calcular X, Y, Z\n",
        "    X = sample_df['num_recommendations'].min()\n",
        "    Y = sample_df['num_recommendations'].max()\n",
        "    Z = sample_df['num_real_purchases'].max()\n",
        "    \n",
        "    print(f\"\\n=== AnÃ¡lisis Muestra de {len(sample_df)} Clientes ===\")\n",
        "    print(f\"Recomendaciones por cliente:\")\n",
        "    print(f\"  - MÃ­nimo: {X}\")\n",
        "    print(f\"  - MÃ¡ximo: {Y}\")\n",
        "    print(f\"  - Promedio: {sample_df['num_recommendations'].mean():.2f}\")\n",
        "    print(f\"\\nCompras reales por cliente:\")\n",
        "    print(f\"  - MÃ¡ximo: {Z}\")\n",
        "    print(f\"  - Promedio: {sample_df['num_real_purchases'].mean():.2f}\")\n",
        "    \n",
        "    print(f\"\\nTexto completo:\")\n",
        "    print(f\"En una muestra de {len(sample_df)} clientes se observa que reciben entre {X} y {Y} \"\n",
        "          f\"recomendaciones, mientras que como mÃ¡ximo compran unos {Z} productos.\")\n",
        "    \n",
        "    return sample_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Contexto:**\n",
        "\n",
        "- El modelo creado categoriza los productos en 5 clases de probabilidad de compra: 'Very Low', 'Low', 'Medium', 'High', 'Very High'.\n",
        "- Para predecir quÃ© clientes comprarÃ­an en la semana siguiente, se seleccionÃ³ aquellas combinaciones cliente-producto clasificadas como 'High' o 'Very High' por el modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ğŸ“Œ Batch 1 (01/01/25 - 05/01/25) [0.75 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cantidad real: 3264\n",
            "cantidad predicha: 12755\n",
            "TP: 1192\n",
            "FP: 11563\n",
            "FN: 2072\n",
            "TN: 1508672\n",
            "{'accuracy': 0.99, 'precision': 0.09, 'recall': 0.37, 'f1': 0.15}\n",
            "\n",
            "=== AnÃ¡lisis por Cliente ===\n",
            "Total clientes con predicciones: 1463\n",
            "Clientes con precisiÃ³n = 0: 916 (62.61%)\n",
            "Clientes con precisiÃ³n > 0.10: 462 (31.58%)\n",
            "\n",
            "=== AnÃ¡lisis Muestra de 50 Clientes ===\n",
            "Recomendaciones por cliente:\n",
            "  - MÃ­nimo: 1\n",
            "  - MÃ¡ximo: 23\n",
            "  - Promedio: 7.46\n",
            "\n",
            "Compras reales por cliente:\n",
            "  - MÃ¡ximo: 13\n",
            "  - Promedio: 1.62\n",
            "\n",
            "Texto completo:\n",
            "En una muestra de 50 clientes se observa que reciben entre 1 y 23 recomendaciones, mientras que como mÃ¡ximo compran unos 13 productos.\n"
          ]
        }
      ],
      "source": [
        "# cÃ³digo para evaluar el performance de su modelo\n",
        "data, preds = load_data(1)\n",
        "\n",
        "# MÃ©tricas globales\n",
        "global_metrics = get_batch_performance(data, preds)\n",
        "print(global_metrics)\n",
        "\n",
        "# AnÃ¡lisis por cliente\n",
        "customer_metrics = analyze_by_customer(data, preds)\n",
        "\n",
        "# AnÃ¡lisis de muestra\n",
        "sample_analysis = analyze_sample_customers(data, preds, sample_size=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cantidad real: 3264\n",
            "cantidad predicha: 7848\n",
            "TP: 859\n",
            "FP: 6989\n",
            "FN: 2405\n",
            "TN: 1513246\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.99, 'precision': 0.11, 'recall': 0.26, 'f1': 0.15}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Filtramos solo Very High\n",
        "preds2 = pd.read_csv(f\"predictions_with_priority/batch_t{1}.csv\")\n",
        "preds2 = preds2[preds2['priority']=='Very High']\n",
        "\n",
        "# MÃ©tricas globales\n",
        "global_metrics2 = get_batch_performance(data, preds2)\n",
        "global_metrics2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El modelo identificÃ³ 12755 productos con prioridad alta o muy alta, mientras que la cantidad real transada fue de 3264.\n",
        "\n",
        "Al compararlas con las compras efectivas se registraron 1192 verdaderos positivos, 11563 falsos positivos, 2072 falsos negativos y 1508672 verdaderos negativos.\n",
        "Con estos valores, la cobertura alcanza alrededor de 37%, lo que indica que el sistema NO recupera la mayor parte de las compras reales. \n",
        "AdemÃ¡s, emite casi 11 recomendaciones por cada interacciÃ³n verdadera, lo que explica la baja precisiÃ³n general (~0,09).\n",
        "\n",
        "El accuracy fue muy alto, pero esto se debe a un desbalance de clases considerable, favoreciendo la clase negativa, en la cual el modelo predice bien la gran mayorÃ­a de los casos.\n",
        "\n",
        "El anÃ¡lisis por cliente revela que mÃ¡s del 60% presenta precisiÃ³n igual a cero y que menos del 40% supera 0,10. Esto muestra que el modelo funciona bien para un grupo reducido, pero para la mayorÃ­a sus aciertos son prÃ¡cticamente aleatorios.\n",
        "\n",
        "En una muestra de 50 clientes se observa que reciben entre 1 y 27 recomendaciones, mientras que como mÃ¡ximo compran unos 16 productos. Esta diferencia confirma que utilizar las clases \"High\" y \"Very High\" como criterio resulta demasiado permisivo y genera un exceso de sugerencias sin relevancia.\n",
        "\n",
        "Al limitar el anÃ¡lisis a la clase \"Very High\", la precisiÃ³n aumenta de 0.09 a 0.11, el F1 se mantiene, y el recall disminuye de 0,37 a 0,26. Este comportamiento indica que aplicar un umbral mÃ¡s exigente , si bien mejorarÃ­a ligeramente la precision, perjudicarÃ­a considerablemente el recall.\n",
        "\n",
        "Desde una perspectiva operativa, si bien emitir 11 recomendaciones por cada compra real resulta viable, podrÃ­a saturar a algunos clientes. \n",
        "Ajustar el umbral de decisiÃ³n pareciera una medida efectiva en este sentido, pues disminuye los falsos positivos casi a la mitad (se realizan menos recomendaciones a clientes que no compraron). Sin embargo, aumentan los falsos negativos y disminuyen los veraderos positivos, haciÃ©ndose menos recomendaciones relevantes, lo que podrÃ­a disminuir las ventas. De antemano pareciera que existe un problema ya sea en el preprocesamiento, es decir, el cÃ³mo se genera la clase \"priority\", y la elecciÃ³n del modelo (KNeighbors Classifier)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ğŸ“Œ Batch 2 (06/01/25 - 12/01/25) [0.75 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cantidad real: 5103\n",
            "cantidad predicha: 12878\n",
            "TP: 1766\n",
            "FP: 11112\n",
            "FN: 3337\n",
            "TN: 1507284\n",
            "{'accuracy': 0.99, 'precision': 0.14, 'recall': 0.35, 'f1': 0.2}\n",
            "\n",
            "=== AnÃ¡lisis por Cliente ===\n",
            "Total clientes con predicciones: 1461\n",
            "Clientes con precisiÃ³n = 0: 671 (45.93%)\n",
            "Clientes con precisiÃ³n > 0.10: 683 (46.75%)\n",
            "\n",
            "=== AnÃ¡lisis Muestra de 50 Clientes ===\n",
            "Recomendaciones por cliente:\n",
            "  - MÃ­nimo: 1\n",
            "  - MÃ¡ximo: 26\n",
            "  - Promedio: 8.26\n",
            "\n",
            "Compras reales por cliente:\n",
            "  - MÃ¡ximo: 14\n",
            "  - Promedio: 3.54\n",
            "\n",
            "Texto completo:\n",
            "En una muestra de 50 clientes se observa que reciben entre 1 y 26 recomendaciones, mientras que como mÃ¡ximo compran unos 14 productos.\n"
          ]
        }
      ],
      "source": [
        "# cÃ³digo para evaluar el performance de su modelo\n",
        "data, preds = load_data(2)\n",
        "\n",
        "# MÃ©tricas globales\n",
        "global_metrics = get_batch_performance(data, preds)\n",
        "print(global_metrics)\n",
        "\n",
        "# AnÃ¡lisis por cliente\n",
        "customer_metrics = analyze_by_customer(data, preds)\n",
        "\n",
        "# AnÃ¡lisis de muestra\n",
        "sample_analysis = analyze_sample_customers(data, preds, sample_size=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cantidad real: 5103\n",
            "cantidad predicha: 7507\n",
            "TP: 1024\n",
            "FP: 6483\n",
            "FN: 4079\n",
            "TN: 1511913\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.99, 'precision': 0.14, 'recall': 0.2, 'f1': 0.16}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Filtramos solo Very High\n",
        "preds2 = pd.read_csv(f\"predictions_with_priority/batch_t{2}.csv\")\n",
        "preds2 = preds2[preds2['priority']=='Very High']\n",
        "\n",
        "# MÃ©tricas globales\n",
        "global_metrics2 = get_batch_performance(data, preds2)\n",
        "global_metrics2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El segundo batch contiene una cantidad real de 5103, mientras que el modelo predice una cantidad de 12878 transacciones. El sistema obtuvo 1766 TP, 11112 FP y 3337 FN. Con estos valores, el recall baja a 0,35, ligeramente bajo el valrr 0,37 del batch 1. La tasa de predicciones disminuye: ahora se producen alrededor de 7 sugerencias por cada caso real (la precisiÃ³n aumenta a  0.14).\n",
        "\n",
        "El porcentaje de clientes con precisiÃ³n igual a 0 disminuye a 45,93%, mientras que el porcentaje de clientes con precisiÃ³n mayor a 10% sube a 46.75%.\n",
        "En la muestra de 50 clientes se vuelve a observar un fuerte desbalance: entre 2 y 29 recomendaciones por cliente frente a un mÃ¡ximo de 15 compras reales.\n",
        "\n",
        "Al limitar la evaluaciÃ³n a la clase \"Very High\", la precisiÃ³n se mantiene en 0.14, el F1 baja a 0.16, y el recall baja a 0.2. \n",
        "Al igual que en el batch 1, si bien esta medida erradica alrededor de la mitad de falsos positivos, introduce falsos negativos y disminuye verdaderos positivos, perjudicando el desempeÃ±o general.\n",
        "\n",
        "En comparaciÃ³n con la semana previa, el modelo incrementa los TP gracias al mayor historial, sin un aumento en FP, indicando una mejora general. Sin embargo, el modelo aÃºn no logra un buen desempeÃ±o pues la cantidad de FP sigue siendo muy alta. Es posible que esto se deba a los problemas que tiene normalmente KNeighbors Classifier con clases desbalanceadas.\n",
        "\n",
        "A nivel operativo, el riesgo de saturar a los clientes disminuye, aunque sigue existiendo riesgo de saturar a clientes sensibles. Dado que la cantidad mÃ¡xima de recomendaciones ha sido consistentemente mayor a la cantidad mÃ¡xima comprada, una buena medida serÃ­a limitar la cantidad de productos sugeridos por cliente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ğŸ“Œ Batch 03 (13/01/25 - 19/01/25) [0.75 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cÃ³digo para evaluar el performance de su modelo\n",
        "data, preds = load_data(3)\n",
        "\n",
        "# MÃ©tricas globales\n",
        "global_metrics = get_batch_performance(data, preds)\n",
        "print(global_metrics)\n",
        "\n",
        "# AnÃ¡lisis por cliente\n",
        "customer_metrics = analyze_by_customer(data, preds)\n",
        "\n",
        "# AnÃ¡lisis de muestra\n",
        "sample_analysis = analyze_sample_customers(data, preds, sample_size=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filtramos solo Very High\n",
        "preds2 = pd.read_csv(f\"predictions_with_priority/batch_t{3}.csv\")\n",
        "preds2 = preds2[preds2['priority']=='Very High']\n",
        "\n",
        "# MÃ©tricas globales\n",
        "global_metrics2 = get_batch_performance(data, preds2)\n",
        "global_metrics2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ğŸ“Œ Batch 04 (20/01/25 - 26/01/25) [0.75 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cÃ³digo para evaluar el performance de su modelo\n",
        "data, preds = load_data(4)\n",
        "\n",
        "# MÃ©tricas globales\n",
        "global_metrics = get_batch_performance(data, preds)\n",
        "print(global_metrics)\n",
        "\n",
        "# AnÃ¡lisis por cliente\n",
        "customer_metrics = analyze_by_customer(data, preds)\n",
        "\n",
        "# AnÃ¡lisis de muestra\n",
        "sample_analysis = analyze_sample_customers(data, preds, sample_size=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filtramos solo Very High\n",
        "preds2 = pd.read_csv(f\"predictions_with_priority/batch_t{4}.csv\")\n",
        "preds2 = preds2[preds2['priority']=='Very High']\n",
        "\n",
        "# MÃ©tricas globales\n",
        "global_metrics2 = get_batch_performance(data, preds2)\n",
        "global_metrics2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ“Œ AnÃ¡lisis comparativo [2.0 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cÃ³digo para realizar anÃ¡lisis de resultados entre batchs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ“Œ Conclusiones y Aprendizajes [1.0 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> [Escriba aquÃ­ sus conclusiones y aprendizajes]\n",
        "\n",
        "\n",
        "Una gran limitante del modelo creado es que este categoriza los productos en clases segÃºn su probabilidad de compra, como se pedÃ­a en el enunciado de la entrega 1. Sin embargo, en esta entrega se evalÃºa el desempeÃ±o de la prediccion de combinaciones cliente-producto que tuvieron transacciones. Para lograr esta conversiÃ³n se definiÃ³ un umbral de corte (seleccionando las combinaciones con clases predichas 'High' y 'Very High'), lo cual introduce un sesgo en las estimaciones.\n",
        "El desempeÃ±o del modelo probablemente habrÃ­a sido mucho mejor si desde un principio se planteaba para predecir directamente \"Compra\" o \"No compra\" para cada combinaciÃ³n cliente-producto.\n",
        "\n",
        "Otra limitaciÃ³n importante es la elecciÃ³n del modelo en si: el modelo k-means se escogiÃ³ por tener el mejor F-1 general (considerando las 5 clases creadas), pero en la prÃ¡ctica solo nos importaba el desempeÃ±o en las clases con mayor prioridad. Este modelo tambiÃ©n obtuvo el mejor F-1 en la clase \"Very High\", pero fue superado por otros como XGboost en \"High\". Si bien XGBoost pudo haber logrado una mejor generalizaciÃ³n, por ser menos sensible al desbalance, lo mÃ¡s probable es que el problema haya sido el preprocesamiento, incluyendo una falta de creaciÃ³n de nuevas features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ Estructura de entrega\n",
        "\n",
        "Se espera que su entrega cuente con la siguiente estructura de carpetas:\n",
        "\n",
        "```bash\n",
        "entrega_3/\n",
        "â”‚\n",
        "â”œâ”€â”€ informe.ipynb # Jupyter notebook con sus resultados\n",
        "â”‚\n",
        "â”œâ”€â”€ predictions/ # Carpeta con las predicciones para cada batch de datos\n",
        "â”‚\n",
        "â””â”€â”€ data/ # Carpeta con los datos realizados (lo que realmente ocurriÃ³)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM6rrqJ85tmz"
      },
      "source": [
        "Mucho Ã©xito!\n",
        "\n",
        "<center>\n",
        "<img src=\"https://gifdb.com/images/high/may-the-force-be-with-you-anakin-skywalker-n2g5o0pm4h6iylsx.gif\" width=\"400\" height=\"300\">\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "deepnote_app_layout": "powerful-article",
    "deepnote_app_reactivity_enabled": true,
    "deepnote_notebook_id": "2939a76dd7c14f7f948714e40aa8bd20",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
